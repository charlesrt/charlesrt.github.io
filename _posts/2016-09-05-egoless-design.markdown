---
layout: post
title:  "Egoless design"
date:   2016-09-05 17:30:00 +0000
categories: leadership, design, ux
image: egoless-design.png
---

![A dark circle on a light background](/assets/2016/09/egoless-design/egoless-design.png)

Back in March, I attended Cross Government Design Meeting #13 (unlucky for some). These events are held for designers from different government departments to get together in person, learn more about what else is going on and feel part of a growing community. Often on the agenda is a great opportunity to get a deep dive into a service that another department is working on. 

Deep dives benefit both sides; the audience gets a chance to see how another team has used design to solve a problem, the presenters get to have many fresh eyes review the thing they’ve made. It’s a space where everyone can learn, if it’s done the right way.

I was half-way through a deep dive at this event.  I became uncomfortable. I was nervous. I was hot. I started breathing heavily. My heart started racing. But-I was not presenting. I was in the audience. An audience that was not doing it the right way. An audience that was criticising.

> Nobody benefits from criticism.


## Crit(ique) vs Crit(icism)

These two words are too similar in form to appreciate their difference in definition. The language we use is important as it dictates our understanding and approach to a situation. This is why I’m going to use the softer word review, which works better.

## Reviewing the right way

When we review the design of a service we should not make statements or pass comments, we should ask questions to learn more.

> How might you...?
Why did you…?
What did the user…?

As designers it’s easy to try to **think** like the user, but we are not, and we can never hope to fully grasp the context of a service in the space of an hour. This is something we should trust the team with. They are the ones that have lived and breathed the service for over a dozen weekly sprints. They are the ones that have attended and observed hundreds of user research sessions. They are the professionals that have been hired and entrusted to do the job the right way.

By asking questions, we prompt answers that will force the team to explain the context and process in more detail. This helps them discovery new ideas or alternative approaches they’d previously missed because they were too focussed. Self-captured comments will always be better acted upon.

It’s also important to talk about what works well. Don’t forget that this is a chance for both sides to learn something new.

## Back in the room

So, disappointingly this wasn’t the way the audience approached the deep dive I attended, which made me feel uncomfortable. Not just because I disagreed with what was happening, and failed nervously to jump to anyones defence (sorry), but because designing in government comes with a luxury that not all designers get to experience — we conduct research with real users. 

All good designers want to prove their assumptions through validation with real users. Unfortunately, many work in environments where this isn’t an option unless something goes live, and that’s only if they’ve managed to battle the subjective opinion of their peers, marketing, IT and the HiPPOs (highest paid persons opinion) on the committee in meeting after meeting.

Working in an environment like that has it’s own challenges when it comes to design reviews, or more often **crits**, and designers don’t have the luxury of user research to backup their solution.

So, when we work in an environment that not only budgets for user research, but commends it as the highest principal to adhere to, we shouldn’t take that for granted by thinking we know best. We should be better than that.

## Why bang on about it now?

Sadly it’s still happening — months later in a Slack chat as part of prep for a service assessment. The point of controversy this time was that some interactions and “visual treatment” were not the same as they are on other government services. But — that’s OK. That’s a question that should be asked as part of the assessment. 

We have assessments at key stages during a project lifecycle to measure the teams progress against a list of guiding principals. Like the deep dives, they help the team get an external view on what’s going well and what may need changing. However — like the audience in the deep dives, it’s the approach of the assessor that is probably more important than the assessment itself. 

Services should be assessed/reviewed based on how well they work for their users, not critiqued/criticised based on subjective opinion. Assessors should ask open questions to learn more, and they may make recommendations off the back for the team to take away and explore further.

Assessors should **not** have a subjectively predetermined agenda to know a good reason why a service has done something differently. It’s probably an introvert vs extrovert thing, but that’s a story for another time.

Services are designed and built at different times and at different paces. It’s not right to assume they should all be the same. The users aren’t the same. Plus it’s good to experiment and try something new. That’s how we learn.

## Being consistent, not uniform

Part of the problem is born from the misused application of design patterns.
Right now, it seems like everyone is talking about patterns, but not everyone is talking about them consistently. 

Patterns are the collaborative design work we all do that make consistently repeatable solutions to common problems. Patterns should not be treated as regimented rules. 

Consistent is about being adaptable, with recognisable similarities that are relevant to the situation.

Uniform is inflexible, not tailored and shoe horned.

> Good patterns are a solution to a recurring design problem, such that you could use the solution many times and never use it in the same way twice.

Patterns — like everything — may need to adapt and evolve to fit the context. They should iterate over time as we experiment and learning something new.

## Skip to the end

There are no bonus points for egos. We’re all working towards the same goal— we all want to solve the problem. It doesn’t matter what it looks like, or how it **feels**. It matters how it works; how people understand it and how people interact with it.

---

*As a bit of a footnote, I wasn’t sure what the title of this story should be. I played with a few options before settling on Egoless design, but at the end of the day it could just as easily have been any of these.*

Objective design
or
Altruistic design
or
Principal design
or simply,
Good design.
