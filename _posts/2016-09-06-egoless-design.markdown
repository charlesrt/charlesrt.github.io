---
title: Egoless design
date: 2016-09-06 12:30:00 Z
categories:
- Design,
- UX,
- Product
- Ego,
- Design
- Patterns
layout: post
image: egoless-design.png
---

![A light circle on a dark background](/assets/2016/09/egoless-design/egoless-design.png)

Back in March, I attended Cross Government Design Meeting #13 (unlucky for some). These events are held for designers from different government departments to get together in person, learn more about what else is going on and feel part of a growing community. Often on the agenda is a great opportunity to get a deep dive into a service that another department is working on.Â 

Deep dives benefit both sides; the audience gets a chance to see how another team has used design to solve a problem, the presenters get to have many fresh eyes review the thing theyâ€™ve made. Itâ€™s a space where everyone can learn, if itâ€™s done the right way.

I was halfway through a deep dive at this event.  I became uncomfortable. I was nervous. I was hot. I started breathing heavily. My heart started racing. But---I was not presenting. I was in the audience. An audience that was not doing it the right way. An audience that was criticising.

Nobody benefits from criticism.

## Crit(ique) vs Crit(icism)

These two words are too similar in form to appreciate their difference in definition. The language we use is important as it dictates our understanding and approach to a situation. This is why Iâ€™m going to use the softer word review, which works better.

## Reviewing the rightÂ way

When we review the design of a service we should not make statements or pass comments, we should ask questions to learn more:

- How might you...?
- Why did you...?
- What did the user...?

As designers itâ€™s easy to try to **think** like the user, but we are not, and we can never hope to fully grasp the context of a service in the space of an hour. This is something we should trust the team with. They are the ones that have lived and breathed the service for over a dozen weekly sprints. They are the ones that have attended and observed hundreds of user research sessions. They are the professionals that have been hired and entrusted to do the job the right way.

By asking questions, we prompt answers that will force the team to explain the context and process in more detail. This helps them discovery new ideas or alternative approaches theyâ€™d previously missed because they were too focussed. Self--captured comments will always be better acted upon.

Itâ€™s also important to talk about what works well. Donâ€™t forget that this is a chance for both sides to learn something new.

## Back in theÂ room

So, disappointingly this wasnâ€™t the way the audience approached the deep dive I attended, which made me feel uncomfortable. Not just because I disagreed with what was happening, and failed nervously to jump to anyones defence (sorry), but because designing in government comes with a luxury that not all designers get to experience---we conduct research with real users.Â 

All good designers want to prove their assumptions through validation with real users. Unfortunately, many work in environments where this isnâ€™t an option unless something goes live, and thatâ€™s only if theyâ€™ve managed to battle the subjective opinion of their peers, marketing, IT and the HiPPOs (highest paid persons opinion) on the committee in meeting after meeting.

Working in an environment like that has itâ€™s own challenges when it comes to design reviews, or more often **crits**, and designers donâ€™t have the luxury of user research to backup their solution.

So---when we work in an environment that not only budgets for user research, but commends it as the highest principal to adhere to, we shouldnâ€™t take that for granted by thinking we know best. We should be better than that.

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Disappointing to see such a subjective opinion on marriage allowance. I thought we were better than that. Keep going James+team ğŸ‘ <a href="https://twitter.com/hashtag/govdesign?src=hash">#govdesign</a></p>&mdash; Charles RT (@charles_rt) <a href="https://twitter.com/charles_rt/status/707964380294545408">March 10, 2016</a></blockquote> <script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

## Why bang on about itÂ now?

Sadly itâ€™s still happening, months later in conversations about service assessments. The controversial opinion is that interactions and â€œvisual treatmentâ€ are not the same as they are on other government services. But---thatâ€™s OK. Thatâ€™s a question that should be asked as part of the assessment.Â 

We have assessments at key stages during a project lifecycle to measure the teams progress against a list of guiding principals. Like the deep dives, they help the team get an external view on whatâ€™s going well and what may need changing. However---like the audience in the deep dives, itâ€™s the approach of the assessor that is probably more important than the assessment itself.Â 

Services should be assessed/reviewed based on how well they work for their users, not critiqued/criticised based on subjective opinion. Assessors should ask open questions to learn more, and they may make recommendations off the back for the team to take away and explore further.

Assessors should **not** have a subjectively predetermined agenda to know a good reason why a service has done something differently. *Itâ€™s probably an introvert vs extrovert thing, but thatâ€™s a story for another time.*

Services are designed and built at different times and at different paces. Itâ€™s not right to assume they should all be the same. The users arenâ€™t the same. Plus itâ€™s good to experiment and try something new. Thatâ€™s how we learn.

## Being consistent, notÂ uniform

Part of the problem is born from the misused application of design patterns.

Right now, it seems like everyone is talking about patterns, but not everyone is talking about them consistently.Â 

Patterns are the collaborative design work we all do that make consistently repeatable solutions to common problems. Patterns should not be treated as regimented rules.Â 

Being consistent is about being adaptable, with recognisable similarities that are relevant to the situation, whereas uniform is inflexible, not tailored and shoe horned.

Good patterns are,

> a solution to a recurring design problem, such that you could use the solution many times and never use it in the same wayÂ twice. ---<cite>Modular Web Design, Nathan Curtis</cite>

When discussing the use of patterns we should do so with this in mind and not mandate their application in a particular fashion because we think we know best.

Patterns---like everything---may need to adapt and evolve to fit the context. They should iterate over time as we experiment and learn something new.

## Skip to theÂ end

There are no bonus points for egos. Weâ€™re all working towards the same goal---we all want to solve the problem. It doesnâ€™t matter what it looks like, or how it **feels**. It matters how it works; how people understand it and how people interact with it.

Ask questions. Listen. Learn. Repeat.

---

*As a bit of a footnote, I wasnâ€™t sure what the title of this story should be. I played with a few options before settling on Egoless design, but at the end of the day it could just as easily have been any of these:*

- ObjectiveÂ design
- AltruisticÂ design
- PrincipalÂ design

Or simply, **GoodÂ design**.
